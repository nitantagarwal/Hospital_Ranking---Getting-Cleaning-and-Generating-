{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing required packages \n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import string\n",
    "import csv\n",
    "from os import rename\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "#Creating a sub-directory\n",
    "staging_dir_name = \"staging\"\n",
    "os.mkdir(staging_dir_name)\n",
    "os.path.isdir(staging_dir_name)\n",
    "\n",
    "#Downloading zip file from url and unzipping it in the staging directoy\n",
    "url = \"https://data.medicare.gov/views/bg9k-emty/files/0a9879e0-3312-4719-a1db-39fd114890f1?content_type=application%2Fzip%3B%20charset%3Dbinary&filename=Hospital_Revised_Flatfiles.zip\"\n",
    "r = requests.get(url)\n",
    "zip_file_name = os.path.join(staging_dir_name,\"Hospital_Revised_Flatfiles.zip\")\n",
    "zip_file_name\n",
    "zf = open(zip_file_name,\"wb\")\n",
    "zf.write(r.content)\n",
    "zf.close()\n",
    "z = zipfile.ZipFile(zip_file_name, \"r\")\n",
    "z.extractall(staging_dir_name)\n",
    "z.close()\n",
    "\n",
    "#Defining Functions\n",
    "\n",
    "#The clean function helps in cleaning table names and column names\n",
    "def clean(x):\n",
    "    x = x.lower()\n",
    "    x = x.replace(\" \", \"_\") \n",
    "    x = x.replace(\"-\", \"_\")\n",
    "    x = x.replace(\"%\", \"pct\")\n",
    "    x = x.replace(\"/\", \"_\")\n",
    "    if x[0].isalpha() == False:\n",
    "        x = \"t_\" + x\n",
    "    return x\n",
    "\n",
    "#function to get only csv names from the full path list\n",
    "def get_csv_names(a):\n",
    "    #s = str(a)\n",
    "    x = a.rfind(\"\\\\\")\n",
    "    return(x + 1)\n",
    "\n",
    "#function to remove single quotes from names\n",
    "def removequotes(x):\n",
    "    z=x.replace(\"'\",'')\n",
    "    return (z)\n",
    "\n",
    "#reading all the csv files\n",
    "rwd = os.getcwd()\n",
    "swd = os.getcwd()+\"/staging\"\n",
    "os.chdir(swd)\n",
    "file = glob.glob(\"*.csv\")\n",
    "\n",
    "#removing corrupt file\n",
    "if('FY2015_Percent_Change_in_Medicare_Payments.csv' in file):\n",
    "    os.remove('FY2015_Percent_Change_in_Medicare_Payments.csv')\n",
    "    files.remove('FY2015_Percent_Change_in_Medicare_Payments.csv')\n",
    "    \n",
    "#getting csv names after cleaning it\n",
    "list_files = glob.glob(\"*.csv\")\n",
    "for lname in list_files:\n",
    "    rename(lname, lname.replace(lname,clean(lname)))\n",
    "list_files = glob.glob(\"*.csv\")\n",
    "\n",
    "\n",
    "#getting full path along with the csv names\n",
    "full_path_list = []\n",
    "for a in list_files:\n",
    "    full_path_list.append(os.getcwd()+\"\\\\\"+a)\n",
    "    \n",
    "#going back to local directory\n",
    "os.chdir(\"..\")\n",
    "\n",
    "#Changing the encoding of files to make it python compatible\n",
    "for enc in full_path_list:\n",
    "    inp_files = open(enc,\"rt\", encoding='cp1252')\n",
    "    i_data = inp_files.read()\n",
    "    inp_files.close()\n",
    "    out_files = open(enc,\"wt\", encoding='utf-8')\n",
    "    for c in i_data:\n",
    "        if c !='\\0':\n",
    "            out_files.write(c)\n",
    "    out_files.close()\n",
    "\n",
    "#creating database and setting up a connection    \n",
    "conn = sqlite3.connect(\"medicare_hospital_compare.db\")\n",
    "curs = conn.cursor()\n",
    "\n",
    "#Creating and loading tables\n",
    "for file_name in full_path_list:\n",
    "    list1 = []\n",
    "    tablename = []\n",
    "    with open(file_name, encoding='utf-8') as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter = ',')\n",
    "        for row in readCSV:\n",
    "            list1.append(row)\n",
    "    list1[0] = [clean(a) for a in list1[0]]\n",
    "    x = get_csv_names(file_name)\n",
    "    tablename = file_name[x:]\n",
    "    tablename = tablename[:-4]\n",
    "    tablename = removequotes(tablename)\n",
    "    curs.execute(\"create table if not exists \" +tablename + \" (\" + \",\".join(str(a + \" text\") for a in list1[0])+\");\")\n",
    "    #i=1\n",
    "    #j=len(list1)\n",
    "    if (tablename != 'psi_april2017') and (tablename != 'mort_readm_april2017'):\n",
    "        i=1\n",
    "        j=len(list1)\n",
    "        while (i<j):\n",
    "            list1[i]=[removequotes(f) for f in list1[i]]\n",
    "            curs.execute(\"insert into \"+  tablename +\" values(\"+ ','.join(str(\"'\"+k+\"'\") for k in list1[i]) +')')\n",
    "            i+=1;\n",
    "    else:\n",
    "        i=1\n",
    "        j=len(list1)-2\n",
    "        while (i<(j)):\n",
    "            list1[i]=[removequotes(f) for f in list1[i]]\n",
    "            curs.execute(\"insert into \"+ tablename +\" values(\"+ ','.join(str(\"'\"+k+\"'\") for k in list1[i]) +')')\n",
    "            i+=1;\n",
    "    list1[:] = []\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "#Part 1 END\n",
    "\n",
    "#Part 2 START\n",
    "\n",
    "#gettting the hospital ranking file from url and reading it\n",
    "url_1 = \"http://kevincrook.com/utd/hospital_ranking_focus_states.xlsx\"\n",
    "x1 = pd.ExcelFile(url_1)\n",
    "\n",
    "#connecting to the database\n",
    "conn = sqlite3.connect(\"medicare_hospital_comapre.db\")\n",
    "curs = conn.cursor()\n",
    "\n",
    "#getting sheets as dataframes\n",
    "sheet = x1.sheet_names\n",
    "hospital_ranking = x1.parse(sheet[0])\n",
    "focus_states = x1.parse(sheet[1])\n",
    "\n",
    "# Reading the required csv files with rankings and making it ready to use\n",
    "query = (\"SELECT * FROM hospital_general_information;\")\n",
    "result = pd.read_sql_query(query,conn)\n",
    "result['provider_id'] = pd.to_numeric(result['provider_id'])\n",
    "result.rename(columns={'provider_id':'Provider ID'}, inplace = True)\n",
    "df1 = result[[\"Provider ID\",\"hospital_name\", \"city\", \"state\", \"county_name\"]]\n",
    "\n",
    "#Merging 2 data frames and sorting it\n",
    "National_Hospital_Rannkin = hospital_ranking.merge(df1, left_on = 'Provider ID', right_on = 'Provider ID', how = 'left', left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=False, indicator=False)\n",
    "sorted_national_ranking = National_Hospital_Rannkin.reindex(National_Hospital_Rannkin.Ranking.sort_values().index)\n",
    "sorted_national_ranking.drop('Ranking', axis = 1, inplace = True)\n",
    "national_top100 = sorted_national_ranking.head(100)\n",
    "\n",
    "#Creating excel file with national hospital ranking\n",
    "national_top100.columns = ['Provider ID', 'Hospital Name', 'City','State','County']\n",
    "writer = pd.ExcelWriter('hospital_ranking.xlsx', engine='xlsxwriter')\n",
    "national_top100.to_excel(writer, sheet_name = 'Nationwide', index = False)\n",
    "\n",
    "# Getting the top 100 state wise hospital ranking for states of interest and writing it in excel\n",
    "focus_states.sort_values(by = 'State Name', ascending = True, inplace = True, axis = 0)\n",
    "for index, row in focus_states.iterrows():\n",
    "    df103 = National_Hospital_Rannkin.loc[National_Hospital_Rannkin['state'] == row['State Abbreviation']]\n",
    "    df103 = df103.head(100)\n",
    "    # Convert the dataframe to an XlsxWriter Excel object.\n",
    "    df103.to_excel(writer, sheet_name=row['State Name'], index = False)\n",
    "\n",
    "writer.close()\n",
    "writer.save()\n",
    "\n",
    "#Part 2 END\n",
    "\n",
    "#Part 3 START\n",
    "#Quering and reading the required file\n",
    "score_query = (\"select state, measure_id, measure_name, cast(score as int) score from timely_and_effective_care___hospital where score not in ('Not Available');\")\n",
    "score = pd.read_sql_query(score_query,conn)\n",
    "\n",
    "#grouping and creating aggregate measures\n",
    "nation_score = score.sort_values('measure_id').groupby(['measure_id','measure_name']).agg({'score':['min','max','mean','std']})\n",
    "nation_score = pd.DataFrame(nation_score.to_records())\n",
    "\n",
    "\n",
    "#Creating columns and writiing the data to excel nationwide\n",
    "nation_score.columns=['Measure ID', 'Measure Name', 'Minimum','Maximum','Average','Standard Deviation']\n",
    "writer = pd.ExcelWriter('measure_statistics.xlsx', engine = 'xlsxwriter')\n",
    "nation_score.to_excel(writer,'Nationwide', index = False)\n",
    "\n",
    "#Getting the top 100 state wise hospital measures for states of interest and writing it in excel\n",
    "for index, row in focus_states.iterrows():\n",
    "    df12 = score.loc[score['state'] == row['State Abbreviation']]\n",
    "    df12 = df12.sort_values('measure_id').groupby(['measure_id','measure_name']).agg({'score':['min','max','mean','std']})\n",
    "    df12 = pd.DataFrame(df12.to_records())\n",
    "    df12.columns=['Measure ID', 'Measure Name', 'Minimum','Maximum','Average','Standard Deviation']\n",
    "    df12.to_excel(writer, sheet_name=row['State Name'], index = False)\n",
    "    \n",
    "writer.close()\n",
    "writer.save()\n",
    "\n",
    "#Part 3 END\n",
    "#END"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
